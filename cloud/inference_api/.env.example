# ─── Nku Cloud Inference API — Environment Variables ───
# Copy this file to .env and fill in your values.
# All variables have safe defaults except NKU_API_KEY and HF_TOKEN.
#
# NOTE: The cloud API is a development/prototyping artifact.
# Production inference is 100% on-device (Android).

# ── Server ──
APP_ENV=production          # production | development
DEBUG=false                 # true → bypasses API key check (dev only)
PORT=8080                   # HTTP listen port
LOG_LEVEL=INFO              # Python logging level
LOG_JSON=true               # JSON-structured logs (recommended for Cloud Run)

# ── Authentication ──
NKU_API_KEY=                # Required in production. Clients send via X-API-Key header.

# ── HuggingFace ──
HF_TOKEN=                   # Required to download gated models (MedGemma, TranslateGemma)
# HUGGINGFACE_TOKEN=        # Alternative env var name (checked as fallback)

# ── Model Configuration ──
MEDGEMMA_REPO=wredd/MedGemma-1.5-4B-PT-GGUF
MEDGEMMA_FILE=MedGemma-1.5-4B-PT-Q2_K.gguf
TRANSLATEGEMMA_REPO=wredd/TranslateGemma-4B-GGUF
TRANSLATEGEMMA_FILE=TranslateGemma-4B-Q2_K.gguf
MODEL_CONTEXT_SIZE=2048     # Max context window (tokens)
MODEL_THREADS=4             # CPU threads for inference

# ── Inference Parameters ──
TRANSLATION_TEMPERATURE=0.3
TRIAGE_TEMPERATURE=0.2
MAX_TRANSLATION_TOKENS=256
MAX_TRIAGE_TOKENS=512

# ── Rate Limiting ──
ENABLE_RATE_LIMITING=true
RATE_LIMIT_PER_MINUTE=30
RATE_LIMIT_PER_HOUR=500

# ── Redis (optional — enables distributed rate limiting) ──
# REDIS_URL=                # Full Redis URL (redis://host:port)
# REDISHOST=                # Alternative: Redis hostname
# REDISPORT=6379            # Alternative: Redis port

# ── Input Validation ──
MAX_TEXT_LENGTH=2000         # Max chars for translation input
MAX_SYMPTOM_LENGTH=1000     # Max chars for triage symptom input

# ── CORS ──
ALLOWED_ORIGINS=            # Comma-separated origins, e.g. https://nku.app,http://localhost:3000
